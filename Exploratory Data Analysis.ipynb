{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset\n",
    "\n",
    "\n",
    "In this notebook, we will perform an EDA (Exploratory Data Analysis) on the processed Waymo dataset (data in the `processed` folder). In the first part, you will create a function to display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading unweighted datasets: ['PROCESSED TF RECORD PATH']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['PROCESSED TF RECORD PATH']\n",
      "INFO:tensorflow:Number of filenames to read: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Did not find any input files matching the glob pattern ['PROCESSED TF RECORD PATH']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/app/project/Exploratory Data Analysis.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f766967696c616e745f6b68617979616d227d/app/project/Exploratory%20Data%20Analysis.ipynb#ch0000002vscode-remote?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m get_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mPROCESSED TF RECORD PATH\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/app/project/utils.py:24\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(tfrecord_path, label_map)\u001b[0m\n\u001b[1;32m     21\u001b[0m input_config\u001b[39m.\u001b[39mlabel_map_path \u001b[39m=\u001b[39m label_map\n\u001b[1;32m     22\u001b[0m input_config\u001b[39m.\u001b[39mtf_record_input_reader\u001b[39m.\u001b[39minput_path[:] \u001b[39m=\u001b[39m [tfrecord_path]\n\u001b[0;32m---> 24\u001b[0m dataset \u001b[39m=\u001b[39m build_dataset(input_config)\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:244\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(input_reader_config, batch_size, transform_input_data_fn, input_context, reduce_to_frame_fn)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m input_context \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m   batch_size \u001b[39m=\u001b[39m input_context\u001b[39m.\u001b[39mget_per_replica_batch_size(batch_size)\n\u001b[0;32m--> 244\u001b[0m dataset \u001b[39m=\u001b[39m read_dataset(\n\u001b[1;32m    245\u001b[0m     functools\u001b[39m.\u001b[39;49mpartial(tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mTFRecordDataset, buffer_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m1000\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m1000\u001b[39;49m),\n\u001b[1;32m    246\u001b[0m     config\u001b[39m.\u001b[39;49minput_path[:], input_reader_config, filename_shard_fn\u001b[39m=\u001b[39;49mshard_fn)\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m input_reader_config\u001b[39m.\u001b[39msample_1_of_n_examples \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    248\u001b[0m   dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mshard(input_reader_config\u001b[39m.\u001b[39msample_1_of_n_examples, \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:164\u001b[0m, in \u001b[0;36mread_dataset\u001b[0;34m(file_read_func, input_files, config, filename_shard_fn)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m   tf\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mReading unweighted datasets: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m input_files)\n\u001b[0;32m--> 164\u001b[0m   \u001b[39mreturn\u001b[39;00m _read_dataset_internal(file_read_func, input_files,\n\u001b[1;32m    165\u001b[0m                                 config\u001b[39m.\u001b[39;49mnum_readers, config, filename_shard_fn)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:83\u001b[0m, in \u001b[0;36m_read_dataset_internal\u001b[0;34m(file_read_func, input_files, num_readers, config, filename_shard_fn)\u001b[0m\n\u001b[1;32m     81\u001b[0m tf\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mNumber of filenames to read: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(filenames))\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filenames:\n\u001b[0;32m---> 83\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDid not find any input files matching the glob pattern \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     84\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(input_files))\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m num_readers \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(filenames):\n\u001b[1;32m     86\u001b[0m   num_readers \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(filenames)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Did not find any input files matching the glob pattern ['PROCESSED TF RECORD PATH']"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(\"/app/project/data/processed/*.tfrecord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to display an image and the bounding boxes\n",
    "\n",
    "Implement the `display_instances` function below. This function takes a batch as an input and display an image with its corresponding bounding boxes. The only requirement is that the classes should be color coded (eg, vehicles in red, pedestrians in blue, cyclist in green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(batch):\n",
    "    \"\"\"\n",
    "    This function takes a batch from the dataset and display the image with \n",
    "    the associated bounding boxes.\n",
    "    \"\"\"\n",
    "    colors = {1: 'red', 2: 'blue', 4: 'green'}\n",
    "    \n",
    "    image = batch['image'].numpy()\n",
    "    bboxes = batch['groundtruth_boxes'].numpy()\n",
    "    classes = batch['groundtruth_classes'].numpy()\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    # resize bboxes\n",
    "    bboxes[:, [0, 2]] *= h\n",
    "    bboxes[:, [1, 3]] *= w\n",
    "    \n",
    "    \n",
    "    f, ax = plt.subplots(1, figsize=(10,10))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for bb, cl in zip(bboxes, classes):\n",
    "        y1, x1, y2, x2 = bb\n",
    "        rec = Rectangle((x1, y1), x2 - x1, y2 - y1, facecolor='none', edgecolor=colors[cl], linewidth = 2)\n",
    "        ax.add_patch(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 10 images \n",
    "\n",
    "Using the dataset created in the second cell and the function you just coded, display 10 random images with the associated bounding boxes. You can use the methods `take` and `shuffle` on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 10 random images in dataset\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    for batch in dataset.shuffle(75, reshuffle_each_iteration=True).take(1):\n",
    "        display_instances(batch)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EDA\n",
    "\n",
    "In this last part, you are free to perform any additional analysis of the dataset. What else would like to know about the data?\n",
    "For example, think about data distribution. So far, you have only looked at a single file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
